{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJWL1K9SthY4JE3jve00ru",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sd8738/Sumant/blob/main/Customer_Sentiment_Watchdog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCjIHZxAfyoz",
        "outputId": "50dd0217-8e0f-4103-c593-fb49b27f5057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies first:\n",
        "# pip install fastapi uvicorn transformers torch\n",
        "\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from transformers import pipeline\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load Hugging Face Model\n",
        "# -------------------------------\n",
        "# Load HF_TOKEN from Colab secrets to address the warning\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "if HF_TOKEN:\n",
        "    os.environ['HF_TOKEN'] = HF_TOKEN\n",
        "\n",
        "emotion_analyzer = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
        "    return_all_scores=True\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Initialize FastAPI App\n",
        "# -------------------------------\n",
        "app = FastAPI(title=\"Customer Sentiment Watchdog\",\n",
        "              description=\"API for real-time emotion detection in customer messages\",\n",
        "              version=\"1.0\")\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Define Input Schema\n",
        "# -------------------------------\n",
        "class Message(BaseModel):\n",
        "    text: str\n",
        "\n",
        "# -------------------------------\n",
        "# 4. API Endpoint\n",
        "# -------------------------------\n",
        "@app.post(\"/analyze_emotion\")\n",
        "def analyze_emotion(message: Message):\n",
        "    results = emotion_analyzer(message.text)[0]\n",
        "\n",
        "    # Sort by highest score\n",
        "    sorted_results = sorted(results, key=lambda x: x['score'], reverse=True)\n",
        "    top_emotion = sorted_results[0]\n",
        "\n",
        "    return {\n",
        "        \"text\": message.text,\n",
        "        \"detected_emotion\": top_emotion['label'],\n",
        "        \"confidence\": round(top_emotion['score'], 3),\n",
        "        \"all_emotions\": {res['label']: round(res['score'], 3) for res in results}\n",
        "    }\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Run server (from terminal)\n",
        "# -------------------------------\n",
        "# uvicorn filename:app --reload"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies (only once)\n",
        "# pip install transformers torch\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load a pretrained emotion classification model\n",
        "# This model is trained to detect multiple emotions\n",
        "emotion_analyzer = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
        "    top_k=None\n",
        ")\n",
        "\n",
        "# Function to analyze emotions\n",
        "def analyze_emotion(text):\n",
        "    results = emotion_analyzer(text)[0]\n",
        "\n",
        "    # Sort emotions by score\n",
        "    sorted_results = sorted(results, key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "    # Pick the top emotion\n",
        "    top_emotion = sorted_results[0]\n",
        "\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"detected_emotion\": top_emotion['label'],\n",
        "        \"confidence\": round(top_emotion['score'], 3),\n",
        "        \"all_emotions\": {res['label']: round(res['score'], 3) for res in results}\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Hda6rzNqnDl",
        "outputId": "49d93ba0-9eb1-49f0-e35d-ac90f46c8b4c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies (only once)\n",
        "# pip install transformers torch\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load a pretrained emotion classification model\n",
        "# This model is trained to detect multiple emotions\n",
        "emotion_analyzer = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
        "    return_all_scores=True\n",
        ")\n",
        "\n",
        "# Function to analyze emotions\n",
        "def analyze_emotion(text):\n",
        "    results = emotion_analyzer(text)[0]\n",
        "\n",
        "    # Sort emotions by score\n",
        "    sorted_results = sorted(results, key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "    # Pick the top emotion\n",
        "    top_emotion = sorted_results[0]\n",
        "\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"detected_emotion\": top_emotion['label'],\n",
        "        \"confidence\": round(top_emotion['score'], 3),\n",
        "        \"all_emotions\": {res['label']: round(res['score'], 3) for res in results}\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNYCW_gPuWUW",
        "outputId": "dd3c1ff3-672e-4008-9fb5-2d9f0e82858a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    }
  ]
}